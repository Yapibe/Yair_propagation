{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mygene"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T18:42:13.004852200Z",
     "start_time": "2024-01-13T18:42:12.997823400Z"
    }
   },
   "id": "63c43c78a44412db",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_and_filter_data(file_path):\n",
    "    # Load data from the file\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Create a copy of the DataFrame\n",
    "    temp_df = df.copy()\n",
    "\n",
    "    # print how many rows in df_nm have a p-value lower than 0.05\n",
    "    print(temp_df[temp_df['P-value (500nM vs T)'] < 0.05].shape)\n",
    "\n",
    "    # In column 'Gbkey' only keep rows with value: 'Gene | mRNA'\n",
    "    temp_df = temp_df[temp_df['Gbkey'] == 'Gene | mRNA']\n",
    "    # Remove column 'Gbkey'\n",
    "    temp_df.drop(columns=['Gbkey'], inplace=True)\n",
    "    \n",
    "    # remove any row if the value in column gene_symbol does not start with a letter\n",
    "    temp_df = temp_df[temp_df['Gene_Symbol'].str[0].str.isalpha()]\n",
    "    # turn all values in Human_Name column to uppercase if they are letters, some values are a combination of letters and numbers\n",
    "    temp_df['Gene_Symbol'] = temp_df['Gene_Symbol'].str.upper()\n",
    "    \n",
    "    # check how many duplicate values in Gene_Symbol column\n",
    "    print('Number of duplicate values in Gene_Symbol column: ', temp_df.duplicated(subset=['Gene_Symbol']).sum())\n",
    "    \n",
    "    # create list of all Human_Name values\n",
    "    query_list = temp_df['Gene_Symbol'].tolist()\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    \n",
    "    df = mg.querymany(query_list, scopes='symbol', fields='symbol,entrezgene', species='human', entrezonly=True, verbose=True, as_dataframe=True)\n",
    "    # Rename the columns in df for clarity\n",
    "    df.rename(columns={'symbol': 'Gene_Symbol', 'entrezgene': 'GeneID'}, inplace=True)\n",
    "    \n",
    "    # Merge temp_df with df to get the GeneID\n",
    "    merged_df = pd.merge(temp_df, df[['Gene_Symbol', 'GeneID']], on='Gene_Symbol', how='left')\n",
    "    \n",
    "    # create df from the dict_list\n",
    "    print(merged_df.shape)\n",
    "    print(merged_df.head())\n",
    "    # check if df has duplicates\n",
    "    print('Number of duplicate values in Gene_Symbol column: ', merged_df.duplicated(subset=['GeneID']).sum())\n",
    "    # change order of columns\n",
    "    merged_df = merged_df[['GeneID', 'Gene_Symbol', 'P-value (T vs N)', 'Score (T vs N)', 'P-value (500nM vs T)', 'Score (500nM vs T)']]\n",
    "    # change column name from Gene_Symbol to Human_Name\n",
    "    merged_df.rename(columns={'Gene_Symbol': 'Human_Name'}, inplace=True)\n",
    "    return merged_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T20:56:48.529248800Z",
     "start_time": "2024-01-13T20:56:48.475590800Z"
    }
   },
   "id": "3ebaf06ee8bd80e9",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_idmap(file_path):\n",
    "    id_file = pd.read_excel(file_path)\n",
    "    id_file_copy = id_file.copy()\n",
    "    # # print file name \n",
    "    # print(file_path)\n",
    "    # print(id_file.shape)\n",
    "    # # print how many duplicate rows there are in the DataFrame\n",
    "    # print('duplicates in the DataFrame Before drop:', id_file.duplicated().sum())\n",
    "    # # delete rows that are duplicates\n",
    "    # id_file.drop_duplicates(inplace=True)\n",
    "    # print('duplicates in the DataFrame After drop:', id_file.duplicated().sum())\n",
    "    # print(id_file.shape)\n",
    "    # # print how many duplicates in the query column\n",
    "    # print('duplicates in the Human_Name column:', id_file['Human_Name'].duplicated().sum())\n",
    "    # print('duplicates in the GeneID column:', id_file['GeneID'].duplicated().sum())\n",
    "    # # print all unique duplicates in the GeneID column\n",
    "    # print('unique duplicates in the GeneID column:', id_file['GeneID'][id_file['GeneID'].duplicated()].unique())\n",
    "    # # # drop duplicates from the query column\n",
    "    # # id_file.drop_duplicates(subset=['query'], inplace=True)\n",
    "    # # # print how duplicated in the query column after dropping duplicates\n",
    "    # # print('duplicates in the query column after dropping duplicates:', id_file['query'].duplicated().sum())\n",
    "    #use mygene to get the gene ID for the gene symbol\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    # create list of all Human_Name values\n",
    "    query_list = id_file['Human_Name'].tolist()\n",
    "    dict_list = mg.querymany(query_list, scopes='symbol', species='human', as_dataframe=True)\n",
    "    # create df from the dict_list\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T16:48:07.442507400Z",
     "start_time": "2024-01-13T16:48:07.393819600Z"
    }
   },
   "id": "b0b6ac62cf56eabb",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def merge_dataframes(df1, df2):\n",
    "    # Merge the two DataFrames\n",
    "    merged_df = pd.concat([df1, df2]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # print how many rows and columns are in the DataFrame\n",
    "    print(merged_df.shape)\n",
    "    # print how many rows have NaN values in the GeneID column\n",
    "    print(merged_df['GeneID'].isna().sum())\n",
    "    # print how many rows have NaN values in the Human_Name column\n",
    "    print(merged_df['Human_Name'].isna().sum())\n",
    "    print('duplicates in the Human_Name column:', merged_df['Human_Name'].duplicated().sum())\n",
    "    print('duplicates in the GeneID column:', merged_df['GeneID'].duplicated().sum())\n",
    "    # print how many whole rows are duplicated\n",
    "    print('duplicates in the DataFrame:', merged_df.duplicated().sum())\n",
    "    return merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T16:16:48.936793200Z",
     "start_time": "2024-01-13T16:16:48.928786700Z"
    }
   },
   "id": "3dac7d3f923a0f48",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 6)\n",
      "Number of duplicate values in Gene_Symbol column:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m dir_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInputs/experiments_data/Parkinson/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m data_file_path \u001B[38;5;241m=\u001B[39m dir_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParkinson_t_v_n_500nm_v_t.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 4\u001B[0m temp_data_file \u001B[38;5;241m=\u001B[39m \u001B[43mload_and_filter_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_file_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# save the filtered data\u001B[39;00m\n\u001B[1;32m      6\u001B[0m temp_data_file\u001B[38;5;241m.\u001B[39mto_excel(dir_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParkinson_t_v_n_500nm_v_t_filtered.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[51], line 27\u001B[0m, in \u001B[0;36mload_and_filter_data\u001B[0;34m(file_path)\u001B[0m\n\u001B[1;32m     24\u001B[0m query_list \u001B[38;5;241m=\u001B[39m temp_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGene_Symbol\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     25\u001B[0m mg \u001B[38;5;241m=\u001B[39m mygene\u001B[38;5;241m.\u001B[39mMyGeneInfo()\n\u001B[0;32m---> 27\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mmg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquerymany\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscopes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msymbol\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfields\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msymbol,entrezgene\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspecies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhuman\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mentrezonly\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_dataframe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Rename the columns in df for clarity\u001B[39;00m\n\u001B[1;32m     29\u001B[0m df\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msymbol\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGene_Symbol\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mentrezgene\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGeneID\u001B[39m\u001B[38;5;124m'\u001B[39m}, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/biothings_client/base.py:575\u001B[0m, in \u001B[0;36mBiothingClient._querymany\u001B[0;34m(self, qterms, scopes, **kwargs)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mquery_fn\u001B[39m(qterms):\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_querymany_inner(qterms, verbose\u001B[38;5;241m=\u001B[39mverbose, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 575\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hits \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_repeated_query(query_fn, qterms, verbose\u001B[38;5;241m=\u001B[39mverbose):\n\u001B[1;32m    576\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m return_raw:\n\u001B[1;32m    577\u001B[0m         out\u001B[38;5;241m.\u001B[39mappend(hits)  \u001B[38;5;66;03m# hits is the raw response text\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/biothings_client/base.py:262\u001B[0m, in \u001B[0;36mBiothingClient._repeated_query\u001B[0;34m(self, query_fn, query_li, verbose, **fn_kwargs)\u001B[0m\n\u001B[1;32m    259\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone.\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(cache_str))\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m from_cache \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelay:\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;66;03m# no need to delay if requests are from cache.\u001B[39;00m\n\u001B[0;32m--> 262\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelay\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "dir_path = 'Inputs/experiments_data/Parkinson/'\n",
    "data_file_path = dir_path + 'Parkinson_t_v_n_500nm_v_t.xlsx'\n",
    "temp_data_file = load_and_filter_data(data_file_path)\n",
    "# save the filtered data\n",
    "temp_data_file.to_excel(dir_path + 'Parkinson_t_v_n_500nm_v_t_filtered.xlsx', index=False)\n",
    "# print how many rows and columns are in the DataFrame\n",
    "print(temp_data_file.shape)\n",
    "print(temp_data_file.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T20:56:57.344747Z",
     "start_time": "2024-01-13T20:56:51.166012300Z"
    }
   },
   "id": "ff3e1ef35deb99c6",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421\n",
      "duplicates in the GeneID column: 0\n",
      "unique duplicates in the GeneID column: []\n"
     ]
    }
   ],
   "source": [
    "# print how many nan values are in the GeneID column\n",
    "print(temp_data_file['GeneID'].isna().sum())\n",
    "# remove rows with nan values in the GeneID column\n",
    "temp_data_file.dropna(subset=['GeneID'], inplace=True)\n",
    "# print how many duplicate values are in the GeneID column\n",
    "print('duplicates in the GeneID column:', temp_data_file['GeneID'].duplicated().sum())\n",
    "# print the unique duplicate values in the GeneID column\n",
    "print('unique duplicates in the GeneID column:', temp_data_file['GeneID'][temp_data_file['GeneID'].duplicated()].unique())\n",
    "# save the filtered data\n",
    "temp_data_file.to_excel(dir_path + 'Parkinson_t_v_n_500nm_v_t_filtered.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T18:44:29.069119400Z",
     "start_time": "2024-01-13T18:44:27.768732300Z"
    }
   },
   "id": "98cc1439271b0a23",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 4)\n",
      "(14274, 4)\n",
      "(14274, 4)\n",
      "duplicates in the GeneID column: 0\n",
      "duplicates in the GeneID column: 0\n",
      "unique duplicates in the GeneID column: []\n",
      "unique duplicates in the GeneID column: []\n",
      "93\n",
      "duplicates in the GeneID column: 0\n",
      "unique duplicates in the GeneID column: []\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "dir_path = 'Inputs/experiments_data/Parkinson/'\n",
    "T_v_N_file = dir_path + 'roded_T_v_N.xlsx'\n",
    "nm_file = dir_path + 'roded_500nm.xlsx'\n",
    "\n",
    "# read the files\n",
    "df_T_v_N = pd.read_excel(T_v_N_file)\n",
    "df_nm = pd.read_excel(nm_file)\n",
    "\n",
    "# print how many rows in df_nm have a p-value lower than 0.05\n",
    "print(df_nm[df_nm['P-value'] < 0.05].shape)\n",
    "\n",
    "# print how many rows and columns are in the DataFrames\n",
    "print(df_T_v_N.shape)\n",
    "print(df_nm.shape)\n",
    "\n",
    "# print how many duplicate values are in the GeneID column\n",
    "print('duplicates in the GeneID column:', df_T_v_N['GeneID'].duplicated().sum())\n",
    "print('duplicates in the GeneID column:', df_nm['GeneID'].duplicated().sum())\n",
    "\n",
    "# print the unique duplicate values in the GeneID column\n",
    "print('unique duplicates in the GeneID column:', df_T_v_N['GeneID'][df_T_v_N['GeneID'].duplicated()].unique())\n",
    "print('unique duplicates in the GeneID column:', df_nm['GeneID'][df_nm['GeneID'].duplicated()].unique())\n",
    "\n",
    "# how many nan values are in the Human_Name column\n",
    "print(df_T_v_N['Human_Name'].isna().sum())\n",
    "\n",
    "# Convert 'GeneID' in df_T_v_N to string format\n",
    "df_T_v_N['GeneID'] = df_T_v_N['GeneID'].astype(str)\n",
    "\n",
    "# Iterate over df_T_v_N to update 'Human_Name'\n",
    "for index, row in df_T_v_N.iterrows():\n",
    "    if pd.isna(row['Human_Name']) and row['GeneID'] in temp_data_file['GeneID'].values:\n",
    "        # Find the corresponding 'Human_Name' from temp_data_file using 'GeneID'\n",
    "        matching_row = temp_data_file[temp_data_file['GeneID'] == row['GeneID']]\n",
    "        if not matching_row.empty:\n",
    "            # Update the 'Human_Name' in df_T_v_N\n",
    "            df_T_v_N.at[index, 'Human_Name'] = matching_row['Human_Name'].iloc[0]\n",
    "# print how many duplicate values are in the GeneID column\n",
    "print('duplicates in the GeneID column:', df_T_v_N['GeneID'].duplicated().sum())\n",
    "\n",
    "# print the unique duplicate values in the GeneID column\n",
    "print('unique duplicates in the GeneID column:', df_T_v_N['GeneID'][df_T_v_N['GeneID'].duplicated()].unique())\n",
    "\n",
    "# how many nan values are in the Human_Name column\n",
    "print(df_T_v_N['Human_Name'].isna().sum())\n",
    "\n",
    "# save t_v_n data\n",
    "df_T_v_N.to_excel(dir_path + 'roded_T_v_N_filtered.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T20:51:20.511148Z",
     "start_time": "2024-01-13T20:51:14.752056700Z"
    }
   },
   "id": "60fe76196208cb2d",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9 input query terms found dup hits:\t[('ARMCX5-GPRASP2', 2), ('BORCS8-MEF2B', 2), ('BUB1B-PAK6', 2), ('CRYZL2P-SEC16B', 2), ('MICOS10-NBL\n",
      "118 input query terms found no hit:\t['BTBD11', 'C19ORF54', 'C20ORF27', 'SPATA5', 'SPATA5L1', 'C1ORF109', 'FAM172A', 'RNF165', 'C18ORF25'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15662, 7)\n",
      "           _id     _score entrezgene  \\\n",
      "query                                  \n",
      "A1BG         1  19.289219          1   \n",
      "A1CF     29974  17.584267      29974   \n",
      "A2M          2  19.319730          2   \n",
      "A2ML1   144568  18.956692     144568   \n",
      "A4GALT   53947  18.395320      53947   \n",
      "\n",
      "                                                     name  symbol   taxid  \\\n",
      "query                                                                       \n",
      "A1BG                               alpha-1-B glycoprotein    A1BG  9606.0   \n",
      "A1CF                       APOBEC1 complementation factor    A1CF  9606.0   \n",
      "A2M                                 alpha-2-macroglobulin     A2M  9606.0   \n",
      "A2ML1                        alpha-2-macroglobulin like 1   A2ML1  9606.0   \n",
      "A4GALT  alpha 1,4-galactosyltransferase (P1PK blood gr...  A4GALT  9606.0   \n",
      "\n",
      "       notfound  \n",
      "query            \n",
      "A1BG        NaN  \n",
      "A1CF        NaN  \n",
      "A2M         NaN  \n",
      "A2ML1       NaN  \n",
      "A4GALT      NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "496 input query terms found dup hits:\t[('ABCD1', 2), ('ACD', 2), ('ADAM12', 2), ('ADAM1A', 2), ('ADCY8', 2), ('ADRA1D', 2), ('ADSL', 2), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13983, 6)\n",
      "            _id     _score entrezgene  \\\n",
      "query                                   \n",
      "A2M           2  19.329280          2   \n",
      "A2ML1    144568  18.965952     144568   \n",
      "A3GALT2  127550  18.735895     127550   \n",
      "A4GALT    53947  18.396685      53947   \n",
      "A4GNT     51146  18.224072      51146   \n",
      "\n",
      "                                                      name   symbol  taxid  \n",
      "query                                                                       \n",
      "A2M                                  alpha-2-macroglobulin      A2M   9606  \n",
      "A2ML1                         alpha-2-macroglobulin like 1    A2ML1   9606  \n",
      "A3GALT2                  alpha 1,3-galactosyltransferase 2  A3GALT2   9606  \n",
      "A4GALT   alpha 1,4-galactosyltransferase (P1PK blood gr...   A4GALT   9606  \n",
      "A4GNT            alpha-1,4-N-acetylglucosaminyltransferase    A4GNT   9606  \n",
      "(27792, 7)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'GeneID'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3790\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3791\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3792\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:181\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'GeneID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[91], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m file_path_idmap \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData/H_sapiens/gene_names/Copy_of_idmap.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      4\u001B[0m df_idmap1 \u001B[38;5;241m=\u001B[39m load_idmap(file_path_idmap)\n\u001B[0;32m----> 5\u001B[0m df_merged \u001B[38;5;241m=\u001B[39m \u001B[43mmerge_dataframes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_idmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_idmap1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m df_merged\u001B[38;5;241m.\u001B[39mto_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData/H_sapiens/gene_names/idmap_merged.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[74], line 8\u001B[0m, in \u001B[0;36mmerge_dataframes\u001B[0;34m(df1, df2)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(merged_df\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# print how many rows have NaN values in the GeneID column\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmerged_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGeneID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39misna()\u001B[38;5;241m.\u001B[39msum())\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# print how many rows have NaN values in the Human_Name column\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(merged_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHuman_Name\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39misna()\u001B[38;5;241m.\u001B[39msum())\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3893\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3895\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3793\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3794\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3795\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3796\u001B[0m     ):\n\u001B[1;32m   3797\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3798\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3799\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3800\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3801\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'GeneID'"
     ]
    }
   ],
   "source": [
    "file_path_idmap = 'Data/H_sapiens/gene_names/ID_to_Name_Map.xlsx'\n",
    "df_idmap = load_idmap(file_path_idmap)\n",
    "file_path_idmap = 'Data/H_sapiens/gene_names/Copy_of_idmap.xlsx'\n",
    "df_idmap1 = load_idmap(file_path_idmap)\n",
    "df_merged = merge_dataframes(df_idmap, df_idmap1)\n",
    "df_merged.to_excel('Data/H_sapiens/gene_names/idmap_merged.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-13T16:49:52.950956900Z",
     "start_time": "2024-01-13T16:48:10.654527400Z"
    }
   },
   "id": "initial_id",
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "404b507105c2b0e5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'join_dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[67], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df_joined \u001B[38;5;241m=\u001B[39m \u001B[43mjoin_dataframes\u001B[49m(temp_data_file, df_idmap)\n\u001B[1;32m      2\u001B[0m df_final \u001B[38;5;241m=\u001B[39m handle_duplicates(df_joined)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Save the final DataFrame\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'join_dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "df_joined = join_dataframes(temp_data_file, df_idmap)\n",
    "df_final = handle_duplicates(df_joined)\n",
    "\n",
    "# Save the final DataFrame\n",
    "df_final.to_excel('final_output_iPSC.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T16:13:05.827538800Z",
     "start_time": "2024-01-13T16:13:05.824537100Z"
    }
   },
   "id": "f2b974a4699c7175",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ac3b0a8e0d84603"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
